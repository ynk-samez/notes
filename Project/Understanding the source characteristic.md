#ResearchProject #Sorces
## Optimizers
>[! Hint]
>In neural networks, *optimizers* are algorithms that determine _how the modelâ€™s parameters (weights and biases) are updated during training_ so that the loss function is minimized.  
They sit between _gradients_ (computed by backpropagation) and _parameter updates_, deciding the direction, step size, and sometimes the geometry of the update. (wiki)
